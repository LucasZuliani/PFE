{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb47daa9c10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "torch.manual_seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "   print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BCEWithLogitsLoss**\n",
    "\n",
    "This loss function combines a Sigmoid layer and the Binary Cross-Entropy (BCE) loss in one single class, making it suitable for binary classification tasks where the output logits need to be converted to probabilities. It computes the binary cross-entropy between the target and the output logits.\n",
    "\n",
    "**Formula**: \n",
    "$$BCE(x, y) = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[y_i \\cdot \\log(\\sigma(x_i)) + (1 - y_i) \\cdot \\log(1 - \\sigma(x_i))\\right] $$\n",
    "\n",
    "Where:\n",
    "- \\( $x_i$ \\) is the output logit for the \\(i\\)-th sample.\n",
    "- \\( $y_i$ \\) is the target label (0 or 1) for the \\(i\\)-th sample.\n",
    "- \\( $\\sigma(x_i)$ = $\\frac{1}{1 + e^{-x_i}}$ \\) is the Sigmoid function applied to the output logit.\n",
    "\n",
    "**L1Loss**\n",
    "\n",
    "This loss function computes the Mean Absolute Error (MAE) between the predicted output and the target. It is commonly used in regression tasks, where minimizing the absolute difference between predictions and actual values is important.\n",
    "\n",
    "**Formula**: \n",
    "$$L_1Loss(x, y) = \\frac{1}{N} \\sum_{i=1}^{N} |x_i - y_i|$$\n",
    "\n",
    "Where:\n",
    "- \\( $x_i$ \\) is the predicted value for the \\(i\\)-th sample.\n",
    "- \\( $y_i$ \\) is the target value for the \\(i\\)-th sample.\n",
    "- \\( N \\) is the number of samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_criterion = nn.BCEWithLogitsLoss()\n",
    "recon_criterion = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os \n",
    "\n",
    "num_channels = 250\n",
    "prefix = '../DCRM/Data_BC_250'\n",
    "u3val = np.array([sio.loadmat(os.path.join(prefix, \"BCMultiPoissonCalc_\" + str(i) + \".mat\"))['u'] for i in range(1,num_channels+1)]) # solution obtained with DF\n",
    "poisson_f = np.array([sio.loadmat(os.path.join(prefix, \"BCMultiPoissonCalc_\" + str(i) + \".mat\"))['gf'] for i in range(1,num_channels+1)]) # source term\n",
    "\n",
    "inputs = torch.tensor(np.expand_dims(poisson_f, axis=1)) # from (250, 128, 128) to (250, 1, 128, 128)\n",
    "true_sol = torch.tensor(np.expand_dims(u3val, axis=1))\n",
    "BCval = torch.zeros_like(true_sol) # Bcs are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channelsTest = 1000\n",
    "prefixTest = '../DCRM/Data_BC_1000'\n",
    "u3valTest = np.array([sio.loadmat(os.path.join(prefixTest, \"BCMultiPoissonCalc_\" + str(i) + \".mat\"))['u'] for i in range(1,num_channelsTest+1)])\n",
    "poisson_fTest = np.array([sio.loadmat(os.path.join(prefixTest, \"BCMultiPoissonCalc_\" + str(i) + \".mat\"))['gf'] for i in range(1,num_channelsTest+1)])\n",
    "\n",
    "inputsTest = torch.tensor(np.expand_dims(poisson_fTest , axis=1))\n",
    "true_solTest = torch.tensor(np.expand_dims(u3valTest , axis=1))\n",
    "BCvalTest = torch.zeros_like(true_solTest)\n",
    "\n",
    "for i in range(true_solTest .shape[0]):\n",
    "    BCvalTest[i,0,:,:] = true_solTest[i,0,:,:]\n",
    "    BCvalTest[i, 0, 1:127, 1:127] = torch.zeros((126,126))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/.local/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "x = torch.linspace(0, 1, 128 )\n",
    "y = torch.linspace(0, 1, 128 )\n",
    "rx, ry = torch.meshgrid(x, y) # rx is the x component of the meshgrid, ry is the y component of the meshgrid\n",
    "rx = rx.to(device)\n",
    "ry = ry.to(device)\n",
    "\n",
    "# If the tensors are on the GPU, they have to be moved to the CPU to be converted to numpy arrays\n",
    "rxd = rx.cpu().detach().numpy()\n",
    "ryd = ry.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Adam Optimizer\n",
    "\n",
    "The Adam optimizer uses two moments for adjusting learning rates:\n",
    "\n",
    "1. **First Moment (Gradient Mean)**:\n",
    "   - **Effect**: A value close to 1 gives more weight to past gradients, allowing the optimizer to retain a longer-term memory of gradients.\n",
    "\n",
    "2. **Second Moment (Gradient Variance)**:\n",
    "   - **Effect**: Squaring the gradients is used to measure the variance, which helps in adjusting the learning rate adaptively based on the magnitude of gradients.\n",
    "\n",
    "Parameters:\n",
    "- **$\\beta_1$**: Controls the momentum (gradient mean).\n",
    "- **$\\beta_2$**: Controls the variance (squared gradient mean).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network_w import *\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02) # initialize the weights with a normal distribution\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02) \n",
    "        torch.nn.init.constant_(m.bias, 0) # initialize the bias of the batch normalization to zero\n",
    "\n",
    "input_dim = 2\n",
    "real_dim = 1\n",
    "\n",
    "lr = 0.0001\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "\n",
    "gen = UNet(input_dim, real_dim).to(device)\n",
    "gen = gen.apply(weights_init)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Cosine Annealing\n",
    "\n",
    "1. **Why we are using it**:\n",
    "    - Used to dynamically reduce the learning rate of the optimizer during training, **following a cosine curve**. By decreasing the learning rate, it helps avoid saddle points or shallow local minima.\n",
    "2. **Saddle points**:\n",
    "    - Point where the function has different curvatures in different directions, being both convex and concave in various directions\n",
    "    - Result in weak or zero gradients, making it hard to determine the optimal direction for optimization and potentially slowing convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(gen_opt, 300 * 2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Noyaux de convolution\n",
    "\n",
    "1. **Output dimension of an image of size WxH after performing a convolution with a kernel of size $k_h$ x $k_w$**: \n",
    "    - Padding : P and Stride : S\n",
    "    \n",
    "    - H' = $\\frac{H + 2P - k_h}{S} + 1$ \n",
    "\n",
    "    - W' = $\\frac{W + 2P - k_w}{S} + 1$ \n",
    "\n",
    "2. **Paper explanations (for DCPINN)**:\n",
    "    - Laplacian operator discretized spacially by centrale difference schemes :\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Delta u(x, y) & = u_{xx}(x, y) + u_{yy}(x, y) \\\\\n",
    "& \\approx \\frac{u(x -h, y) + u(x + h, y) - 4u(x, y) + u(x, y - h) + u(x,y + h)}{h^2} \\\\\n",
    "& := \\frac{1}{h^2} \\begin{bmatrix}\n",
    "                    0 & 1 & 0 \\\\\n",
    "                    1 & -4 & 1 \\\\\n",
    "                    0 & 1 & 0\n",
    "                    \\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "3. **Paper explanations (for DCRM)**:\n",
    "    - We want to minimise : $E(u) = \\int_0^1 \\int_0^1 (\\frac{1}{2}) \\|\\nabla\\hat{U}\\| - \\hat{U}F - \\int_{|\\partial \\Omega_N}\\hat{U}|_{\\partial \\Omega_N}g_N$\n",
    "    \n",
    "    - We have to approximate : $\\frac{\\partial u}{\\partial x}$ and $\\frac{\\partial u}{\\partial y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stencildudx =np.array(((-3.0,4. , -1.0))) # forward stencil for the x derivative\n",
    "stencildudy =np.array(((-3.0),(4.) ,(-1.0))) # forward stencil for the y derivative\n",
    "\n",
    "stencildudx_2 =np.array(((-1.0,4. , -3.0))) # backward stencil for the x derivative\n",
    "stencildudy_2 =np.array(((-1.0),(4.) ,(-3.0))) # backward stencil for the y derivative\n",
    "\n",
    "def du_dx(index, real_dim):\n",
    "    m = torch.nn.Conv2d(1, 1, (3,1), stride=(1,1), groups=real_dim).to(device) # create a convolutional layer with 1 input channel, 1 output channel, a kernel size of 3x1, and a stride of 1x1\n",
    "\n",
    "    if index == 1: #  initialize the weights of the convolutional layer with the stencil\n",
    "        for i in range(3):\n",
    "            for k in range(1):\n",
    "                m.weight.data[k, 0, i, 0] = stencildudx[i]\n",
    "    else:\n",
    "        for i in range(3):\n",
    "            for k in range(1):\n",
    "                m.weight.data[k, 0, i, 0] = stencildudx_2[i]\n",
    "    m.bias.data = torch.zeros((1))\n",
    "\n",
    "    with torch.autograd.no_grad():\n",
    "        m.weight.requires_grad_(False)\n",
    "        m.bias.requires_grad_(False)\n",
    "\n",
    "    m= m.to(device)\n",
    "    return m\n",
    "\n",
    "def du_dy(index, real_dim):\n",
    "    m = torch.nn.Conv2d(1, 1, (1,3), stride=1, groups=real_dim).to(device)\n",
    "\n",
    "    if index == 1:\n",
    "        for j in range(3):\n",
    "            for k in range(1):\n",
    "                m.weight.data[k, 0, 0, j] = stencildudy[j]\n",
    "    else:\n",
    "        for j in range(3):\n",
    "            for k in range(1):\n",
    "                m.weight.data[k, 0, 0, j] = stencildudy_2[j]\n",
    "\n",
    "    m.bias.data = torch.zeros((1))\n",
    "    with torch.autograd.no_grad():\n",
    "\n",
    "        m.weight.requires_grad_(False)\n",
    "        m.bias.requires_grad_(False)\n",
    "\n",
    "    m= m.to(device)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Train process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = inputs.to(device).float() # source term\n",
    "bc = BCval.to(device).float() # boundary conditions\n",
    "inpComb = torch.cat((condition, bc), 1) # concatenate the source term and the boundary conditions\n",
    "\n",
    "conditionTest = inputsTest.to(device).float()\n",
    "bcTest = BCvalTest.to(device).float()\n",
    "inpCombTest = torch.cat((conditionTest, bcTest), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 - Interpolation on a grid \n",
    "\n",
    "1. **Why we shloud do that** :\n",
    "\n",
    "    - The high-fidelity model is based on computational methods such as FEM (Finite Element Method) or FVM (Finite Volume Method).\n",
    "\n",
    "    - In these numerical simulations, data is often obtained on non-uniform meshes that are adapted to the complex geometry of the domain or are finer in certain areas (local refinement). \n",
    "\n",
    "    - CNNs are designed to process data on a regular grid.\n",
    "\n",
    "2. **Why we choose to not interpolate boundary conditions** :\n",
    "\n",
    "    - Imposed boundary conditions are often specific values or physical behaviors that we want to be strictly adhered to.\n",
    "\n",
    "    - If the boundary conditions are defined on complex geometries (such as curves or non-planar surfaces), interpolation might not faithfully respect the geometric shape of the boundaries.\n",
    "\n",
    "3. **What we interpolate** :\n",
    "\n",
    "    - source term withou bc, solution for training and solution for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata\n",
    "\n",
    "def interpo(condition_st):\n",
    "    n = 128\n",
    "    linx128 = np.linspace(0, 1, n)\n",
    "\n",
    "    linx130 = np.linspace(0, 1, n + 2)\n",
    "    z1_out = np.zeros(((condition_st.shape[0], 1, 130, 130)))\n",
    "    for mm in range(condition_st.shape[0]):\n",
    "        val = condition_st[mm, 0, :, :].detach().cpu().numpy()\n",
    "        xv_128, yv_128 = np.meshgrid(linx128, linx128, indexing='ij')\n",
    "        xv_130, yv_130 = np.meshgrid(linx130, linx130, indexing='ij')\n",
    "\n",
    "        points = np.zeros(( 128 * 128, 2))\n",
    "        values = np.zeros(( 128 * 128, 1))\n",
    "        iter = 0\n",
    "        for i in range(128):\n",
    "            for j in range(128):\n",
    "                points[iter, 0] = xv_128[i, j]\n",
    "                points[iter, 1] = yv_128[i, j]\n",
    "                values[iter, 0] = val[i, j]\n",
    "                iter = iter + 1\n",
    "\n",
    "        grid_z1 = griddata(points, values[:, 0], (xv_130, yv_130), method='linear') # We can change the method : see doc\n",
    "        z1_out[mm,0,:,:] = grid_z1.reshape((1, 1, 130, 130))\n",
    "\n",
    "    return torch.as_tensor(z1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source term is interpolated to 130x130\n",
    "inter_condition = interpo(condition)\n",
    "inter_condition = inter_condition.to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution term for training is interpolated to 130x130\n",
    "inter_true = interpo(true_sol)\n",
    "inter_true = inter_true.to(device).float()\n",
    "inter_true_np = inter_true.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOlution term for testing is interpolated to 130x130\n",
    "inter_trueTest = interpo(true_solTest)\n",
    "inter_trueTest = inter_trueTest.to(device).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 - Grid creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = condition.shape[2]\n",
    "m = condition.shape[3]\n",
    "x = torch.linspace(0, 1, n + 2)\n",
    "y = torch.linspace(0, 1, m + 2)\n",
    "rx, ry = torch.meshgrid(x, y)\n",
    "rx = rx.to(device)\n",
    "ry = ry.to(device)\n",
    "rxd = rx.cpu().detach().numpy()\n",
    "ryd = ry.cpu().detach().numpy()\n",
    "\n",
    "W = torch.zeros((1, 1, rx.shape[0], rx.shape[1]), device=device)\n",
    "\n",
    "x130 = np.linspace(0, 1, 130)\n",
    "deltax130 = np.abs(x130[1] - x130[0])\n",
    "x = np.linspace(0,1,128)\n",
    "deltax = np.abs(x[1] - x[0])\n",
    "\n",
    "convGraddudx = du_dx(1, real_dim)\n",
    "convGraddudy = du_dy(1, real_dim)\n",
    "convGraddudx2 = du_dx(2, real_dim)\n",
    "convGraddudy2 = du_dy(2, real_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 - Dataset creation and training\n",
    "\n",
    "1. **Various steps of the training process** :\n",
    "    - Padding the output of the CNN to impose the boundary conditions\n",
    "\n",
    "    - Compute the approximation of $\\frac{\\partial u}{\\partial x}$ and $\\frac{\\partial u}{\\partial y}$\n",
    "\n",
    "    - Compute the loss E[u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impose_BC(x):\n",
    "    output_CNN = gen(x) # output of the CNN\n",
    "    n = x.shape[2]\n",
    "    m = x.shape[3]\n",
    "    xx = torch.zeros((x.shape[0], 1, n + 2, m + 2)).to(device)\n",
    "\n",
    "    xx[:, :, 1:n + 1, 1:m + 1] = output_CNN # the output of the CNN is placed in the center of the tensor\n",
    "\n",
    "    # Rules defined in the paper for the padding on the sides\n",
    "    xx[:, 0, 0, 1:m + 1] = x[:,1,0, 0:m] \n",
    "    xx[:, 0, n + 1, 1:m + 1] = x[:,1,n-1, 0:m] \n",
    "    xx[:, 0, 1:n + 1, 0] = x[:,1,0:n, 0]\n",
    "    xx[:, 0, 1:n + 1, m + 1] = x[:,1,0:n, m-1]\n",
    "\n",
    "    # Corners : mean of the neighbors\n",
    "    xx[:, 0, 0, m + 1] = 0.5 * (xx[:, 0, 0, m] + xx[:, 0, 1, m + 1])\n",
    "    xx[:, 0, n + 1, 0] = 0.5 * (xx[:, 0, n, 0] + xx[:, 0, n + 1, 1])\n",
    "    xx[:, 0, 0, 0] = 0.5 * (xx[:, 0, 0, 1] + xx[:, 0, 1, 0])\n",
    "    xx[:, 0, n + 1, m + 1] = 0.5 * (xx[:, 0, n + 1, m] + xx[:, 0, n, m + 1])\n",
    "\n",
    "    return xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructor: IntegrationLoss  trapezoidal  in  2  dimension \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22a4e7f7c974d3aad08a08d5dccb4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 3.81 GiB total capacity; 3.03 GiB already allocated; 30.31 MiB free; 3.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [41], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39m(internal1 \u001b[38;5;241m+\u001b[39m internal2) \u001b[38;5;241m-\u001b[39m internal_f\n\u001b[1;32m     45\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 46\u001b[0m \u001b[43mgen_opt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m mean_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     49\u001b[0m mean_loss_compare \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mabs(out \u001b[38;5;241m-\u001b[39m outpt))\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     68\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py:507\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    505\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_sqrt(device_exp_avg_sqs)\n\u001b[1;32m    506\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[0;32m--> 507\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg_sq_sqrt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_addcdiv_(params_, device_exp_avgs, denom, step_size)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 3.81 GiB total capacity; 3.03 GiB already allocated; 30.31 MiB free; 3.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import IntegrationLoss\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch_dataset = TensorDataset(inpComb, inter_true,inter_condition)\n",
    "dataloader = DataLoader(dataset=torch_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "torch_datasetTest = TensorDataset(inpCombTest, inter_trueTest)\n",
    "dataloaderTest = DataLoader(dataset=torch_datasetTest, batch_size=2, shuffle=False)\n",
    "\n",
    "# Training parameters\n",
    "\n",
    "cur_step = 0\n",
    "display_step = 500\n",
    "plot_step = 5000\n",
    "losses_list = []\n",
    "\n",
    "# Loss function\n",
    "intLoss = IntegrationLoss.IntegrationLoss('trapezoidal', 2)\n",
    "\n",
    "while cur_step < 600000:\n",
    "    mean_loss_compare = 0.0\n",
    "    mean_loss = 0.0\n",
    "\n",
    "    for inpt, outpt, inter_out in tqdm(dataloader) :\n",
    "        out = impose_BC(inpt)\n",
    "        out_dudx = (1 / (2 * deltax130)) * convGraddudx(out)\n",
    "        out_dudy = (1 / (2 * deltax130)) * convGraddudy(out)\n",
    "        out_dudx2 = (1 / (2 * deltax130)) * convGraddudx2(out)\n",
    "        out_dudy2 = (1 / (2 * deltax130)) * convGraddudy2(out)\n",
    "\n",
    "        # Loss calculation\n",
    "        I_in1 = torch.pow(out_dudx, 2)\n",
    "        I_in12 = torch.pow(out_dudx2, 2)\n",
    "        I_in2 = torch.pow(out_dudy, 2)\n",
    "        I_in22 = torch.pow(out_dudy2, 2)\n",
    "\n",
    "        internal1 = intLoss.lossInternalEnergy(0.5 * (I_in1 + I_in12), dx=deltax, dy=deltax130, shape=I_in1.shape)\n",
    "        internal2 = intLoss.lossInternalEnergy(0.5 * (I_in2 + I_in22), dx=deltax130, dy=deltax, shape=I_in2.shape)\n",
    "\n",
    "        fu = out * inter_out\n",
    "        internal_f = intLoss.lossInternalEnergy(fu, dx=deltax, dy=deltax, shape=fu.shape)\n",
    "\n",
    "        loss = 0.5*(internal1 + internal2) - internal_f\n",
    "        loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        mean_loss += loss.item()\n",
    "        mean_loss_compare += torch.sum(torch.abs(out - outpt)).item()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
