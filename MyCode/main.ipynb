{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdc75966c10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "torch.manual_seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "   print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BCEWithLogitsLoss**\n",
    "\n",
    "This loss function combines a Sigmoid layer and the Binary Cross-Entropy (BCE) loss in one single class, making it suitable for binary classification tasks where the output logits need to be converted to probabilities. It computes the binary cross-entropy between the target and the output logits.\n",
    "\n",
    "**Formula**: \n",
    "$$BCE(x, y) = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[y_i \\cdot \\log(\\sigma(x_i)) + (1 - y_i) \\cdot \\log(1 - \\sigma(x_i))\\right] $$\n",
    "\n",
    "Where:\n",
    "- \\( $x_i$ \\) is the output logit for the \\(i\\)-th sample.\n",
    "- \\( $y_i$ \\) is the target label (0 or 1) for the \\(i\\)-th sample.\n",
    "- \\( $\\sigma(x_i)$ = $\\frac{1}{1 + e^{-x_i}}$ \\) is the Sigmoid function applied to the output logit.\n",
    "\n",
    "**L1Loss**\n",
    "\n",
    "This loss function computes the Mean Absolute Error (MAE) between the predicted output and the target. It is commonly used in regression tasks, where minimizing the absolute difference between predictions and actual values is important.\n",
    "\n",
    "**Formula**: \n",
    "$$L_1Loss(x, y) = \\frac{1}{N} \\sum_{i=1}^{N} |x_i - y_i|$$\n",
    "\n",
    "Where:\n",
    "- \\( $x_i$ \\) is the predicted value for the \\(i\\)-th sample.\n",
    "- \\( $y_i$ \\) is the target value for the \\(i\\)-th sample.\n",
    "- \\( N \\) is the number of samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_criterion = nn.BCEWithLogitsLoss()\n",
    "recon_criterion = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os \n",
    "\n",
    "num_channels = 10\n",
    "prefix = '../DCRM/Data_BC_250'\n",
    "u3val = np.array([sio.loadmat(os.path.join(prefix, \"BCMultiPoissonCalc_\" + str(i) + \".mat\"))['u'] for i in range(1,num_channels+1)]) # solution obtained with DF\n",
    "poisson_f = np.array([sio.loadmat(os.path.join(prefix, \"BCMultiPoissonCalc_\" + str(i) + \".mat\"))['gf'] for i in range(1,num_channels+1)]) # source term\n",
    "\n",
    "inputs = torch.tensor(np.expand_dims(poisson_f, axis=1)) # from (250, 128, 128) to (250, 1, 128, 128)\n",
    "true_sol = torch.tensor(np.expand_dims(u3val, axis=1))\n",
    "BCval = torch.zeros_like(true_sol) # Bcs are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channelsTest = 100\n",
    "prefixTest = '../DCRM/Data_BC_1000'\n",
    "u3valTest = np.array([sio.loadmat(os.path.join(prefixTest, \"BCMultiPoissonCalc_\" + str(i) + \".mat\"))['u'] for i in range(1,num_channelsTest+1)])\n",
    "poisson_fTest = np.array([sio.loadmat(os.path.join(prefixTest, \"BCMultiPoissonCalc_\" + str(i) + \".mat\"))['gf'] for i in range(1,num_channelsTest+1)])\n",
    "\n",
    "inputsTest = torch.tensor(np.expand_dims(poisson_fTest , axis=1))\n",
    "true_solTest = torch.tensor(np.expand_dims(u3valTest , axis=1))\n",
    "BCvalTest = torch.zeros_like(true_solTest)\n",
    "\n",
    "for i in range(true_solTest .shape[0]):\n",
    "    BCvalTest[i,0,:,:] = true_solTest[i,0,:,:]\n",
    "    BCvalTest[i, 0, 1:127, 1:127] = torch.zeros((126,126))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/.local/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "x = torch.linspace(0, 1, 64 )\n",
    "y = torch.linspace(0, 1, 64 )\n",
    "rx, ry = torch.meshgrid(x, y) # rx is the x component of the meshgrid, ry is the y component of the meshgrid\n",
    "rx = rx.to(device)\n",
    "ry = ry.to(device)\n",
    "\n",
    "# If the tensors are on the GPU, they have to be moved to the CPU to be converted to numpy arrays\n",
    "rxd = rx.cpu().detach().numpy()\n",
    "ryd = ry.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Adam Optimizer\n",
    "\n",
    "The Adam optimizer uses two moments for adjusting learning rates:\n",
    "\n",
    "1. **First Moment (Gradient Mean)**:\n",
    "   - **Effect**: A value close to 1 gives more weight to past gradients, allowing the optimizer to retain a longer-term memory of gradients.\n",
    "\n",
    "2. **Second Moment (Gradient Variance)**:\n",
    "   - **Effect**: Squaring the gradients is used to measure the variance, which helps in adjusting the learning rate adaptively based on the magnitude of gradients.\n",
    "\n",
    "Parameters:\n",
    "- **$\\beta_1$**: Controls the momentum (gradient mean).\n",
    "- **$\\beta_2$**: Controls the variance (squared gradient mean).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network_w import *\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02) # initialize the weights with a normal distribution\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02) \n",
    "        torch.nn.init.constant_(m.bias, 0) # initialize the bias of the batch normalization to zero\n",
    "\n",
    "input_dim = 2\n",
    "real_dim = 1\n",
    "\n",
    "lr = 0.0001\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "\n",
    "gen = UNet(input_dim, real_dim).to(device)\n",
    "gen = gen.apply(weights_init)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Cosine Annealing\n",
    "\n",
    "1. **Why we are using it**:\n",
    "    - Used to dynamically reduce the learning rate of the optimizer during training, **following a cosine curve**. By decreasing the learning rate, it helps avoid saddle points or shallow local minima.\n",
    "2. **Saddle points**:\n",
    "    - Point where the function has different curvatures in different directions, being both convex and concave in various directions\n",
    "    - Result in weak or zero gradients, making it hard to determine the optimal direction for optimization and potentially slowing convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(gen_opt, 300 * 2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Noyaux de convolution\n",
    "\n",
    "1. **Output dimension of an image of size WxH after performing a convolution with a kernel of size $k_h$ x $k_w$**: \n",
    "    - Padding : P and Stride : S\n",
    "    \n",
    "    - H' = $\\frac{H + 2P - k_h}{S} + 1$ \n",
    "\n",
    "    - W' = $\\frac{W + 2P - k_w}{S} + 1$ \n",
    "\n",
    "2. **Paper explanations (for DCPINN)**:\n",
    "    - Laplacian operator discretized spacially by centrale difference schemes :\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Delta u(x, y) & = u_{xx}(x, y) + u_{yy}(x, y) \\\\\n",
    "& \\approx \\frac{u(x -h, y) + u(x + h, y) - 4u(x, y) + u(x, y - h) + u(x,y + h)}{h^2} \\\\\n",
    "& := \\frac{1}{h^2} \\begin{bmatrix}\n",
    "                    0 & 1 & 0 \\\\\n",
    "                    1 & -4 & 1 \\\\\n",
    "                    0 & 1 & 0\n",
    "                    \\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "3. **Paper explanations (for DCRM)**:\n",
    "    - We want to minimise : $E(u) = \\int_0^1 \\int_0^1 (\\frac{1}{2}) \\|\\nabla\\hat{U}\\| - \\hat{U}F - \\int_{|\\partial \\Omega_N}\\hat{U}|_{\\partial \\Omega_N}g_N$\n",
    "    \n",
    "    - We have to approximate : $\\frac{\\partial u}{\\partial x}$ and $\\frac{\\partial u}{\\partial y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stencildudx =np.array(((-3.0,4. , -1.0))) # forward stencil for the x derivative\n",
    "stencildudy =np.array(((-3.0),(4.) ,(-1.0))) # forward stencil for the y derivative\n",
    "\n",
    "stencildudx_2 =np.array(((-1.0,4. , -3.0))) # backward stencil for the x derivative\n",
    "stencildudy_2 =np.array(((-1.0),(4.) ,(-3.0))) # backward stencil for the y derivative\n",
    "\n",
    "def du_dx(index, real_dim):\n",
    "    m = torch.nn.Conv2d(1, 1, (3,1), stride=(1,1), groups=real_dim).to(device) # create a convolutional layer with 1 input channel, 1 output channel, a kernel size of 3x1, and a stride of 1x1\n",
    "\n",
    "    if index == 1: #  initialize the weights of the convolutional layer with the stencil\n",
    "        for i in range(3):\n",
    "            for k in range(1):\n",
    "                m.weight.data[k, 0, i, 0] = stencildudx[i]\n",
    "    else:\n",
    "        for i in range(3):\n",
    "            for k in range(1):\n",
    "                m.weight.data[k, 0, i, 0] = stencildudx_2[i]\n",
    "    m.bias.data = torch.zeros((1))\n",
    "\n",
    "    with torch.autograd.no_grad():\n",
    "        m.weight.requires_grad_(False)\n",
    "        m.bias.requires_grad_(False)\n",
    "\n",
    "    m= m.to(device)\n",
    "    return m\n",
    "\n",
    "def du_dy(index, real_dim):\n",
    "    m = torch.nn.Conv2d(1, 1, (1,3), stride=1, groups=real_dim).to(device)\n",
    "\n",
    "    if index == 1:\n",
    "        for j in range(3):\n",
    "            for k in range(1):\n",
    "                m.weight.data[k, 0, 0, j] = stencildudy[j]\n",
    "    else:\n",
    "        for j in range(3):\n",
    "            for k in range(1):\n",
    "                m.weight.data[k, 0, 0, j] = stencildudy_2[j]\n",
    "\n",
    "    m.bias.data = torch.zeros((1))\n",
    "    with torch.autograd.no_grad():\n",
    "\n",
    "        m.weight.requires_grad_(False)\n",
    "        m.bias.requires_grad_(False)\n",
    "\n",
    "    m= m.to(device)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Train process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = inputs.to(device).float() # source term\n",
    "bc = BCval.to(device).float() # boundary conditions\n",
    "inpComb = torch.cat((condition, bc), 1) # concatenate the source term and the boundary conditions\n",
    "\n",
    "conditionTest = inputsTest.to(device).float()\n",
    "bcTest = BCvalTest.to(device).float()\n",
    "inpCombTest = torch.cat((conditionTest, bcTest), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 - Interpolation on a grid \n",
    "\n",
    "1. **Why we shloud do that** :\n",
    "\n",
    "    - The high-fidelity model is based on computational methods such as FEM (Finite Element Method) or FVM (Finite Volume Method).\n",
    "\n",
    "    - In these numerical simulations, data is often obtained on non-uniform meshes that are adapted to the complex geometry of the domain or are finer in certain areas (local refinement). \n",
    "\n",
    "    - CNNs are designed to process data on a regular grid.\n",
    "\n",
    "2. **Why we choose to not interpolate boundary conditions** :\n",
    "\n",
    "    - Imposed boundary conditions are often specific values or physical behaviors that we want to be strictly adhered to.\n",
    "\n",
    "    - If the boundary conditions are defined on complex geometries (such as curves or non-planar surfaces), interpolation might not faithfully respect the geometric shape of the boundaries.\n",
    "\n",
    "3. **What we interpolate** :\n",
    "\n",
    "    - source term withou bc, solution for training and solution for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata\n",
    "\n",
    "def interpo(condition_st):\n",
    "    n = 128\n",
    "    linx128 = np.linspace(0, 1, n)\n",
    "\n",
    "    linx130 = np.linspace(0, 1, n + 2)\n",
    "    z1_out = np.zeros(((condition_st.shape[0], 1, 130, 130)))\n",
    "    for mm in range(condition_st.shape[0]):\n",
    "        val = condition_st[mm, 0, :, :].detach().cpu().numpy()\n",
    "        xv_128, yv_128 = np.meshgrid(linx128, linx128, indexing='ij')\n",
    "        xv_130, yv_130 = np.meshgrid(linx130, linx130, indexing='ij')\n",
    "\n",
    "        points = np.zeros(( 128 * 128, 2))\n",
    "        values = np.zeros(( 128 * 128, 1))\n",
    "        iter = 0\n",
    "        for i in range(128):\n",
    "            for j in range(128):\n",
    "                points[iter, 0] = xv_128[i, j]\n",
    "                points[iter, 1] = yv_128[i, j]\n",
    "                values[iter, 0] = val[i, j]\n",
    "                iter = iter + 1\n",
    "\n",
    "        grid_z1 = griddata(points, values[:, 0], (xv_130, yv_130), method='linear') # We can change the method : see doc\n",
    "        z1_out[mm,0,:,:] = grid_z1.reshape((1, 1, 130, 130))\n",
    "\n",
    "    return torch.as_tensor(z1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source term is interpolated to 130x130\n",
    "inter_condition = interpo(condition)\n",
    "inter_condition = inter_condition.to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution term for training is interpolated to 130x130\n",
    "inter_true = interpo(true_sol)\n",
    "inter_true = inter_true.to(device).float()\n",
    "inter_true_np = inter_true.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution term for testing is interpolated to 130x130\n",
    "inter_trueTest = interpo(true_solTest)\n",
    "inter_trueTest = inter_trueTest.to(device).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 - Grid creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = condition.shape[2]\n",
    "m = condition.shape[3]\n",
    "x = torch.linspace(0, 1, n + 2)\n",
    "y = torch.linspace(0, 1, m + 2)\n",
    "rx, ry = torch.meshgrid(x, y)\n",
    "rx = rx.to(device)\n",
    "ry = ry.to(device)\n",
    "rxd = rx.cpu().detach().numpy()\n",
    "ryd = ry.cpu().detach().numpy()\n",
    "\n",
    "W = torch.zeros((1, 1, rx.shape[0], rx.shape[1]), device=device)\n",
    "\n",
    "x130 = np.linspace(0, 1, 130)\n",
    "deltax130 = np.abs(x130[1] - x130[0])\n",
    "x = np.linspace(0,1,128)\n",
    "deltax = np.abs(x[1] - x[0])\n",
    "\n",
    "convGraddudx = du_dx(1, real_dim)\n",
    "convGraddudy = du_dy(1, real_dim)\n",
    "convGraddudx2 = du_dx(2, real_dim)\n",
    "convGraddudy2 = du_dy(2, real_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 - Dataset creation and training\n",
    "\n",
    "1. **Various steps of the training process** :\n",
    "    - Padding the output of the CNN to impose the boundary conditions\n",
    "\n",
    "    - Compute the approximation of $\\frac{\\partial u}{\\partial x}$ and $\\frac{\\partial u}{\\partial y}$\n",
    "\n",
    "    - Compute the loss E[u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impose_BC(x):\n",
    "    output_CNN = gen(x) # output of the CNN\n",
    "    n = x.shape[2]\n",
    "    m = x.shape[3]\n",
    "    xx = torch.zeros((x.shape[0], 1, n + 2, m + 2)).to(device)\n",
    "\n",
    "    xx[:, :, 1:n + 1, 1:m + 1] = output_CNN # the output of the CNN is placed in the center of the tensor\n",
    "\n",
    "    # Rules defined in the paper for the padding on the sides\n",
    "    xx[:, 0, 0, 1:m + 1] = x[:,1,0, 0:m] \n",
    "    xx[:, 0, n + 1, 1:m + 1] = x[:,1,n-1, 0:m] \n",
    "    xx[:, 0, 1:n + 1, 0] = x[:,1,0:n, 0]\n",
    "    xx[:, 0, 1:n + 1, m + 1] = x[:,1,0:n, m-1]\n",
    "\n",
    "    # Corners : mean of the neighbors\n",
    "    xx[:, 0, 0, m + 1] = 0.5 * (xx[:, 0, 0, m] + xx[:, 0, 1, m + 1])\n",
    "    xx[:, 0, n + 1, 0] = 0.5 * (xx[:, 0, n, 0] + xx[:, 0, n + 1, 1])\n",
    "    xx[:, 0, 0, 0] = 0.5 * (xx[:, 0, 0, 1] + xx[:, 0, 1, 0])\n",
    "    xx[:, 0, n + 1, m + 1] = 0.5 * (xx[:, 0, n + 1, m] + xx[:, 0, n, m + 1])\n",
    "\n",
    "    return xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructor: IntegrationLoss  trapezoidal  in  2  dimension \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae1bd84b85940e999ab476a14f017ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1236, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630f4f4c3b15480d98904edb7d7bdc9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m     loss_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inpt_test, outpt_test \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloaderTest):\n\u001b[0;32m---> 60\u001b[0m         out_test \u001b[38;5;241m=\u001b[39m \u001b[43mimpose_BC\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m         loss_test \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mabs(out_test \u001b[38;5;241m-\u001b[39m outpt_test))\n\u001b[1;32m     63\u001b[0m mean_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m display_step\n",
      "Cell \u001b[0;32mIn [16], line 2\u001b[0m, in \u001b[0;36mimpose_BC\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimpose_BC\u001b[39m(x):\n\u001b[0;32m----> 2\u001b[0m     output_CNN \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# output of the CNN\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     n \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      4\u001b[0m     m \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/PFE/MyCode/network_w.py:122\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    120\u001b[0m x4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontract4(x3)\n\u001b[1;32m    121\u001b[0m x5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontract5(x4)\n\u001b[0;32m--> 122\u001b[0m x6 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontract6\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m x7 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand0(x6, x5)\n\u001b[1;32m    124\u001b[0m x8 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand1(x7, x4)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/PFE/MyCode/network_w.py:41\u001b[0m, in \u001b[0;36mContractingBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[1;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(x)\n\u001b[0;32m---> 41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bn:\n\u001b[1;32m     43\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchnorm(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import IntegrationLoss\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch_dataset = TensorDataset(inpComb, inter_true,inter_condition)\n",
    "dataloader = DataLoader(dataset=torch_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "torch_datasetTest = TensorDataset(inpCombTest, inter_trueTest)\n",
    "dataloaderTest = DataLoader(dataset=torch_datasetTest, batch_size=2, shuffle=False)\n",
    "\n",
    "# Training parameters\n",
    "\n",
    "cur_step = 0\n",
    "display_step = 100\n",
    "plot_step = 50\n",
    "losses_list = []\n",
    "\n",
    "# Loss function\n",
    "intLoss = IntegrationLoss.IntegrationLoss('trapezoidal', 2)\n",
    "\n",
    "# Plots\n",
    "idx_plot = [0, 5, 9]\n",
    "\n",
    "while cur_step < 500:\n",
    "    mean_loss_compare = 0.0\n",
    "    mean_loss = 0.0\n",
    "\n",
    "    for inpt, outpt, inter_out in tqdm(dataloader) :\n",
    "        out = impose_BC(inpt)\n",
    "        out_dudx = (1 / (2 * deltax130)) * convGraddudx(out)\n",
    "        out_dudy = (1 / (2 * deltax130)) * convGraddudy(out)\n",
    "        out_dudx2 = (1 / (2 * deltax130)) * convGraddudx2(out)\n",
    "        out_dudy2 = (1 / (2 * deltax130)) * convGraddudy2(out)\n",
    "\n",
    "        # Loss calculation\n",
    "        I_in1 = torch.pow(out_dudx, 2)\n",
    "        I_in12 = torch.pow(out_dudx2, 2)\n",
    "        I_in2 = torch.pow(out_dudy, 2)\n",
    "        I_in22 = torch.pow(out_dudy2, 2)\n",
    "\n",
    "        internal1 = intLoss.lossInternalEnergy(0.5 * (I_in1 + I_in12), dx=deltax, dy=deltax130, shape=I_in1.shape)\n",
    "        internal2 = intLoss.lossInternalEnergy(0.5 * (I_in2 + I_in22), dx=deltax130, dy=deltax, shape=I_in2.shape)\n",
    "\n",
    "        fu = out * inter_out\n",
    "        internal_f = intLoss.lossInternalEnergy(fu, dx=deltax, dy=deltax, shape=fu.shape)\n",
    "\n",
    "        loss = 0.5*(internal1 + internal2) - internal_f\n",
    "        loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        mean_loss += loss.item()\n",
    "        mean_loss_compare += torch.sum(torch.abs(out - outpt)).item()\n",
    "\n",
    "        if cur_step % display_step == 0 :\n",
    "            with torch.no_grad():\n",
    "                loss_test = torch.tensor(0.0, requires_grad=False).to(device)\n",
    "                for inpt_test, outpt_test in tqdm(dataloaderTest):\n",
    "                    out_test = impose_BC(inpt_test)\n",
    "                    loss_test += torch.sum(torch.abs(out_test - outpt_test))\n",
    "\n",
    "            mean_loss /= display_step\n",
    "            mean_loss_compare /= display_step\n",
    "            losses_list.append([cur_step, mean_loss, mean_loss_compare, loss_test.item()])\n",
    "            with open('../DCRM/Images/energy_loss.pickle', 'wb') as f:\n",
    "                pickle.dump(losses_list, f)\n",
    "\n",
    "            print(f\"Step {cur_step}: Generator loss: {mean_loss}, Compare loss: {mean_loss_compare}, Test loss: {loss_test}\")\n",
    "\n",
    "        if cur_step % plot_step == 0 :\n",
    "            with torch.no_grad():\n",
    "                out_cnn = impose_BC(inpComb[idx_plot, :, :, :])\n",
    "            out_cnn_np = out_cnn.cpu().detach().numpy()\n",
    "\n",
    "            for xi in range(len(idx_plot)):\n",
    "                fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                im0 = axs[0].imshow(inter_true_np[idx_plot[xi], 0, :, :], cmap='jet')\n",
    "                axs[0].set_title('True solution')\n",
    "                fig.colorbar(im0, ax=axs[0])\n",
    "                im1 = axs[1].imshow(out_cnn_np[xi, 0, :, :], cmap='jet')\n",
    "                axs[1].set_title('Predicted solution')\n",
    "                fig.colorbar(im1, ax=axs[1])\n",
    "                im2 = axs[2].imshow(np.abs(inter_true_np[idx_plot[xi], 0, :, :] - out_cnn_np[xi, 0, :, :]), cmap='jet')\n",
    "                axs[2].set_title('Difference')\n",
    "                fig.colorbar(im2, ax=axs[2])\n",
    "                plt.savefig(f'../DCRM/Images/energy_{cur_step}_{idx_plot[xi]}.png')\n",
    "                plt.close()\n",
    "\n",
    "        cur_step += 1\n",
    "            \n",
    "\n",
    "                \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
