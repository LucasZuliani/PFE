{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "   print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres du modèle\n",
    "N = 2 # dim de l'input x\n",
    "m = 10 # dim de l'output y\n",
    "T = 1 # borne sup pour x\n",
    "nb_points = 10 \n",
    "nb_maps = 100 # nombre d'images que l'on va générer\n",
    "nb_blocks = 2 # nombre de blocs dans le modèle\n",
    "M = 10 # nombre d'échantillons pour l'approximation de Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3993, 0.7746],\n",
      "         [0.8363, 0.7717],\n",
      "         [0.6391, 0.3520],\n",
      "         ...,\n",
      "         [0.8841, 0.8166],\n",
      "         [0.7123, 0.7780],\n",
      "         [0.0135, 0.0353]],\n",
      "\n",
      "        [[0.8790, 0.9101],\n",
      "         [0.1632, 0.4167],\n",
      "         [0.4842, 0.3484],\n",
      "         ...,\n",
      "         [0.4323, 0.9838],\n",
      "         [0.6947, 0.9691],\n",
      "         [0.8011, 0.9819]],\n",
      "\n",
      "        [[0.8550, 0.1772],\n",
      "         [0.8089, 0.7241],\n",
      "         [0.2256, 0.5109],\n",
      "         ...,\n",
      "         [0.3120, 0.8858],\n",
      "         [0.8807, 0.2471],\n",
      "         [0.3191, 0.8327]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5937, 0.7349],\n",
      "         [0.8617, 0.3459],\n",
      "         [0.9040, 0.2119],\n",
      "         ...,\n",
      "         [0.3611, 0.2821],\n",
      "         [0.4607, 0.2944],\n",
      "         [0.9514, 0.7599]],\n",
      "\n",
      "        [[0.1060, 0.0364],\n",
      "         [0.8852, 0.4874],\n",
      "         [0.5199, 0.2959],\n",
      "         ...,\n",
      "         [0.9905, 0.3666],\n",
      "         [0.2988, 0.6709],\n",
      "         [0.4042, 0.8248]],\n",
      "\n",
      "        [[0.6239, 0.9388],\n",
      "         [0.8745, 0.9800],\n",
      "         [0.8333, 0.9794],\n",
      "         ...,\n",
      "         [0.6759, 0.8917],\n",
      "         [0.3519, 0.8139],\n",
      "         [0.6936, 0.1299]]])\n",
      "La dimension de x est torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "omega = torch.tensor([[0, 1] for _ in range(N)])\n",
    "X = torch.zeros((nb_maps, nb_points, N))\n",
    "\n",
    "for _ in range(nb_maps):\n",
    "    x = torch.rand(nb_points, N) * (omega[:, 1] - omega[:, 0]) + omega[:, 0] # all the coordinates of x are between 0 and 1\n",
    "    X[_, :, :] = x\n",
    "X = torch.Tensor(np.expand_dims(X, axis=1))\n",
    "print(f'La dimension de x est {x.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(torch.nn.Module):\n",
    "    def __init__(self, m) -> None:\n",
    "        super(Block, self).__init__()\n",
    "        self.fc = torch.nn.Linear(m, m)\n",
    "        self.activation = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x)\n",
    "        return x + identity\n",
    "    \n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, N, m, nb_blocks) -> None:\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.Linear(N, m)(x)\n",
    "        for _ in range(nb_blocks):\n",
    "            x = Block(10)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x : torch.Tensor, dx = True, delta : float = 1/nb_points) -> torch.Tensor:\n",
    "    if dx:\n",
    "        convx = torch.zeros(x.shape)\n",
    "        for i in range(x.shape[0]):\n",
    "            for j in range(x.shape[1]):\n",
    "                if j == 0 :\n",
    "                    convx[i, j] = (x[i, j+1] - x[i, j])/delta # forward \n",
    "                elif j == x.shape[1] - 1:\n",
    "                    convx[i, j] = (x[i, j] - x[i, j-1])/delta # backward\n",
    "                else:\n",
    "                    convx[i, j] = (x[i, j+1] - x[i, j-1])/(2*delta) # central\n",
    "        return convx\n",
    "    else:\n",
    "        convy = torch.zeros(x.shape)\n",
    "        for i in range(x.shape[0]):\n",
    "            for j in range(x.shape[1]):\n",
    "                if i == 0 :\n",
    "                    convy[i, j] = (x[i+1, j] - x[i, j])/delta # forward\n",
    "                elif i == x.shape[0] - 1:\n",
    "                    convy[i, j] = (x[i, j] - x[i-1, j])/delta # backward\n",
    "                else:\n",
    "                    convy[i, j] = (x[i+1, j] - x[i-1, j])/(2*delta) # central\n",
    "        return convy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code simple pour une seule image\n",
    "gen = Model(N, m, nb_blocks)\n",
    "\n",
    "# Monte Carlo\n",
    "for _ in range(10) :\n",
    "    output = gen(x)\n",
    "    output_dx, output_dy = conv(output), conv(output, dx = False)\n",
    "    L1, L2 = torch.pow(output_dx, 2), torch.pow(output_dy, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "gen = Model(N, m, nb_blocks)\n",
    "output = gen(X)\n",
    "output_dX, output_dY = torch.zeros(output.shape), torch.zeros(output.shape)\n",
    "\n",
    "for i, out in enumerate(output) :\n",
    "    output_dx, output_dy = conv(out[0]), conv(out[0], dx = False)\n",
    "    output_dx, output_dy = output_dx.expand(1, 1, -1, -1), output_dy.expand(1, 1, -1, -1)\n",
    "    output_dX[i, :, :, :], output_dY[i, :, :, :] = output_dx, output_dy\n",
    "    \n",
    "L1, L2 = torch.pow(output_dX, 2)/2, torch.pow(output_dY, 2)/2\n",
    "# gen_opt = torch.optim.Adam(gen.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.3533, grad_fn=<SumBackward0>)\n",
      "tensor(-5.2215, grad_fn=<SumBackward0>)\n",
      "tensor(17.6109, grad_fn=<SumBackward0>)\n",
      "tensor(2.1467, grad_fn=<SumBackward0>)\n",
      "tensor(29.6196, grad_fn=<SumBackward0>)\n",
      "tensor(34.3030, grad_fn=<SumBackward0>)\n",
      "tensor(2.3834, grad_fn=<SumBackward0>)\n",
      "tensor(-25.3725, grad_fn=<SumBackward0>)\n",
      "tensor(-34.0533, grad_fn=<SumBackward0>)\n",
      "tensor(-23.9935, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    output = gen(x)\n",
    "    print(output.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
